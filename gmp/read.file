----------------GMP-----------------
线程调度模型(并发模型CSP)
golang的线程调度器

单进程时代：单一执行流程，如果线程阻塞，cpu不释放，浪费资源

多线程/多进程操作系统：cpu可以处理多个进程，单个cpu也就是切片方式(时间切片，超过时间就强制释放cpu，多个cpu也一样，多对多
并发，如果一个进程阻塞，可以切换到另一个进程

进程的切换是要成本，cpu把cpu寄存器中的当前线程的数据保存到内存中，然后从内存中加载另一个进程的数据到cpu中
上下文切换也差不多道理，有复制数据的情况。
切换过程中也叫做cpu的浪费时间
这也正是多进程和多线程的弊端，进程越多，切换浪费就可能越大，切换成本越高，cpu可能只有百分之50的时间在处理程序进程等，百分之50在切换
线程的切换成本比进程小得多
多线程也会带来同步竞争的问题，怎么异步执行，怎么处理同步竞争的问题


一个线程分为内核空间和用户空间，那么可以分成内核线程和用户空间线程，内核线程负责底层的资源(cpu 内存)，用户线程负责程序的业务逻辑，这两个线程又一一绑定
实际上调度单位是线程，也就是内核负责调度线程
上面这个分层是go的思维，内核线程thread，用户空间线程go-routine

在两者之间可以加上一个线程调度器，线程调度器和内核线程绑定，可以有多个用户空间线程，这就是用户级线程模型
问题就是如果某个goroutine阻塞了，会影响到其他goroutine没法获取资源进行运行(线程切换的问题)

如果goroutine和thread一比一，那么线程的切换就要切换底层的thread，成本高，这就是内核级线程模型

两级模型M:N，这时候瓶颈是线程调度器，就看线程调度器做的好不好，也就是一来调度器和算法的好坏

一个进程会有一个主线程，由该线程继续开辟线程，进程获得固定大小的cpu和内存资源，由主线程往下分配



go对线程的处理，goroutine概念，几KB，所以可以大量的goroutine，灵活调度，正常切换

GMP:goroutine machine("物理"处理器，系统级线程thread，内核级，goroutine是用户级线程，从系统级线程这里获取cpu 内存等资源) processor(中间层，逻辑处理器，设置GOMAXPROCS)

全局goroutine队列，P的goroutine队列

启用一个goroutine去运行代码，如果没有空闲的goroutine就新建(go func())


各个M通过操作系统调度器获得cpu 内存等
P和M一一绑定，每个P有自己的goroutine队列(local P 本地队列)
P拿出G到M中执行，或者说获得M的处理
还有一个全局的goroutine队列
一个P同一时间只能处理一个G，所以实际上微观上看，每一时间最高的并行量是GOMAXPROCS
P的数目设置不是越多越好，考虑cpu的总的核数，P是程序运行的时候创建，一般是cpu的内核总数，也可以在程序中使用runtime包来设置(也可以在程序运行钱通过环境变量设置)
local P队列一般最大256个G
新创建的G会优先放到local P中，如果满了，才是全局队列
go语言默认限制10000个M，操作系统很难支撑这样并行量(runtime/debug下的SetMaxThread函数设置，但是一般操作系统开不了这么多的并行量 系统线程)
M是动态的，如果某个M阻塞，其实就是运行goroutine阻塞，会将整个P M G拿出来，也就是断开了local P队列，直到阻塞回复在继续加上local P运行。然后如果这个M拿开了，很可能会开启一个新的M
如果有M空闲了一段时间，那么会回收M，所以gc和GMP调度模型是一块进行的


-------------------------------调度器设计策略---------------------
复用线程
利用并行
抢占
全局G队列

---------------------复用线程----------------------
work stealing机制(别人来偷取)：
比如有一个P空闲，也就是local P空，会去偷取别的P的local P队列中的G来运行

hand off机制(自己丢掉)：
比如有一个G正在获得P实际上是M的处理，但是G阻塞了(比如io chan阻塞)，这时候应该释放处理器，对于go来说处理器是P，
所以释放P，那就是将这个阻塞的G和M绑定，直到回复运行，原本的P和local P队列分离出来到新建或者唤醒一个M上进行处理
所以说P和M不是严格的1：1


-----------------利用并行-------------
GOMAXPROCS
可以设置，一般是cpu的总核数
也可以设置只用一半，那么剩余核数给其他进程使用



------------------------抢占--------------------
其实就是多个G，不管是等待的还是新建，比如他们都要一个cpu(P M)处理，可能每个G获得cpu10ms，可能G已经处理完了，可以是G主动释放，也可能是到时间了，另外的G抢占了这个G的cpu资源
被抢占的继续进入等待队列
这里有算法决定，保证每个G都能合理得到cpu，给新来的多些权重，已有的也要处理好饥饿问题

--------------------全局队列--------------
空闲的P会优先去全局队列中拿G
如果全局队列也是空的，在取steal其他P的本地队列
这里不是G的休眠，G空闲太久会被gc回收












------------------------go指令的调度流程------------
go func(){}()或者go func()
这时候调度器会启用一个goroutine，可以是创建也可以是用一个空闲goroutine来执行这段代码也就是的函数中的内容
如果是新建的G会优先放进local P队列中，如果local P满，然后再考虑放到全局的队列中
过程中的流程和前面一样，最终就是获得P实际就是M的处理，就是指行函数中的代码
同样如果func中阻塞，那么就将这个G和M绑定并且拿出来，然后从休眠的M队列中拿到一个M或者创建一个M来帮定前面被解开的P
如果阻塞的G恢复了，或者cpu时间到了也就是释放时间片了(比如10ms)，那么绑定M就成为空闲的M放进空闲M队列中，G如果还没执行完继续加入G的等待队列
其实G回复是优先找原本的P的local P队列，然后考虑全局队列


-----------------------纠正一点-------------
上面所说的G阻塞，其实如果是chan这些导致的阻塞是G状态改变，然后重新调度
系统调用syscall这些阻塞才会导致P M分离
其实准确来看G是运行在M中的，M从P的队列中拿到G


----------------------go的生命周期------------
启动一个go程序，也就是进程，是如果创建线程的

其实一个进程的如果不开别的线程,可以看做一个进程就是一个线程(主线程)

M0:启动程序后编号为0的主线程
M0保存在全局变量runtime.M0中，负责初始化操作(P local P队列等等，就是调度器的初始化)和启动第一个G
启动第一个G之后，M0就和其他M一样了



G0:每次启动一个M，都会立即创建一个G0的goroutine，每个M都会有自己的G0
G0仅仅用于负责调度G，也就是G0不执行任何函数
G0可以理解为中间状态，比如G1切换到G2，是先切换到G0再切换到G2



大致的流程：程序启动->M0->G0->初始化调度器，也就是全局队列 P local P->启动第一个G，也就是运行main(当然前面是常量 变量 init函数)
->然后G0和M0解绑定，M0开始处理main函数，实际上就是M0绑定某个P，然后将main由某个G来负责运行，这个G放在这个P的local P队列中
后续就是正常的调度了，可能main的G时间片到了那么就释放cpu，然后M0过段时间又继续拿到main的G来处理，这时候的M0就是普通M
(这期间的G的切换需要用到G0，也就是说G0负责了G的调度)


-------------------GMP可视化调试--------------
运行一段代码来观察GMP

代码示例也在这个文件下面